# -*- coding: utf-8 -*-
"""CNN_InceptionResNetV2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VJdXcaXBwhbu8zUrbIA95J-dOovid94b
"""

# Commented out IPython magic to ensure Python compatibility.
# Użycie zapisanych na dysku zdjęć.
!unzip -q '/content/drive/My Drive/train_val_test.zip' -d '/content'
# Load the TensorBoard notebook extension. #%reload_ext tensorboard
# %load_ext tensorboard

from numpy.random import seed
seed(1)
from tensorflow.random import set_seed
set_seed(2)

import os
import itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras import applications
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import Dense, Conv2D, SeparableConv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping
from tensorflow.keras.optimizers import Adamax, Nadam, Ftrl, Adadelta
from tensorflow.keras.regularizers import l1_l2

BATCH_SIZE = 64
EPOCHS = 10
INITIAL_EPOCH = 0
IMG_HEIGHT, IMG_WIDTH, CHANNELS = 220, 220, 3

dir_path = "/content/train_val_test"
root = "/content/drive/My Drive/CNN_InceptionResNetV2/"

train_gen = ImageDataGenerator(rescale=1.0/255.)
val_gen = ImageDataGenerator(rescale=1.0/255.)
test_gen = ImageDataGenerator(rescale=1.0/255.)

train_generator = train_gen.flow_from_directory(
    dir_path + '/train',
    batch_size=BATCH_SIZE,
    shuffle=True,
    color_mode="rgb",
    class_mode='categorical',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=2)
validation_generator = val_gen.flow_from_directory(
    dir_path + '/val',
    batch_size=BATCH_SIZE,
    shuffle=True,
    color_mode="rgb",
    class_mode='categorical',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=2)
test_generator = test_gen.flow_from_directory(
    dir_path + '/test',
    batch_size=1,
    shuffle=False,
    color_mode="rgb",
    class_mode='categorical',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    seed=2)

STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size
STEP_SIZE_VALID = validation_generator.n // validation_generator.batch_size

my_callbacks = [
    ModelCheckpoint(filepath=root + "model.{epoch:02d}.h5",
                    monitor="val_accuracy",
                    mode='max',
                    save_best_only=True,
                    save_weights_only=False,
                    save_freq="epoch",),
    EarlyStopping(monitor="val_loss",
                  patience=5,),
    # TensorBoard(log_dir=root + "logs",
    #             write_images=True,
    #             histogram_freq=3,
    #             embeddings_freq=3),
]

# Ustawienie wartości wag konkretnych klas podczas uczenia.
# Pozwala to wzmacniac straty (loss) wag dla tych klas.
target_names = sorted(os.listdir(dir_path + "/val"))
ref_nums = []
for i in target_names:
    ref_nums.append(len(os.listdir(dir_path + "/val/" + i)))

# ref_nums = [np.float16(max(ref_nums) / i) for i in ref_nums]
ref_nums = [np.float16(np.log2(max(ref_nums) / i) + 1) for i in ref_nums]
class_weight = dict(enumerate(ref_nums))
print(dict(zip(target_names, ref_nums)))

def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):
    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('Klasa rzeczywista')
    plt.xlabel('Klasa predykowana\nSkuteczność={:0.4f}; błąd klasyfikacji={:0.4f}'.format(accuracy, misclass))
    plt.show()

# Użycie zapisanego na dysku modelu.
files = [f for f in sorted(os.listdir(root))]
model_file = files[-1]
INITIAL_EPOCH = int(model_file.split('.')[1])
EPOCHS += INITIAL_EPOCH

model = load_model(root + model_file)
print(f"Wczytanie pliku modelu: {model_file}, z ilością EPOCH: {INITIAL_EPOCH}")

# Wczytanie modelu ale bez ostatnich warstw by je podmienić
base_model = applications.InceptionResNetV2(weights= None, include_top=False, 
                                            input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS))
# Dodanie 2 warstw do wczytanego modelu, uwzględnienie liczbę klas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.7)(x)
predictions = Dense(5, activation= 'softmax')(x)
model = Model(inputs = base_model.input, outputs = predictions)

model.compile(optimizer=Adamax(learning_rate=0.001, 
                               beta_1=0.9, beta_2=0.999, 
                               epsilon=1e-07), 
              loss="categorical_crossentropy", 
              metrics=["accuracy"])

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# Włączenie tensorboard.
# %tensorboard --logdir "/content/drive/My Drive/CNN_InceptionResNetV2/logs"

history = model.fit(train_generator, 
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=validation_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=EPOCHS, 
                    class_weight=class_weight,
                    shuffle=True,
                    callbacks=my_callbacks,
                    initial_epoch=INITIAL_EPOCH,
                    use_multiprocessing=False, verbose=1)

# Sprawdzenie poprawności na danych testowych
test_generator.reset()
STEP_SIZE_TEST = test_generator.n // test_generator.batch_size 
scores = model.evaluate(test_generator, 
                        steps=STEP_SIZE_TEST,
                        verbose=0)
print(model.metrics_names[0] + " = ", scores[0])
print(model.metrics_names[1] + " = ", scores[1])

test_generator.reset()
probabilities = model.predict(test_generator, 
                              steps=STEP_SIZE_TEST,
                              verbose=0)
y_test = probabilities.argmax(axis=1)
y_pred = test_generator.classes
# target_names = sorted(os.listdir(dir_path + "/test"))
target_names = ["klasa F", "klasa N", "klasa Q", "klasa S", "klasa V"]
print(classification_report(y_test, y_pred, target_names=target_names))

cm = confusion_matrix(y_test, y_pred)
plot_confusion_matrix(cm, target_names, title="Macierz pomyłek", cmap=None, normalize=False)

# Trenowanie na danych ze zbioru walidacyjnego.
model.fit(validation_generator, 
          steps_per_epoch=STEP_SIZE_VALID,
          epochs=2, 
          class_weight=class_weight,
          shuffle=True,
          use_multiprocessing=False, verbose=1)

# Sprawdzenie poprawności na danych testowych po trenowaniu na zbiorze walidacyjnym.
test_generator.reset()
STEP_SIZE_TEST = test_generator.n // test_generator.batch_size 
scores = model.evaluate(test_generator, 
                        steps=STEP_SIZE_TEST,
                        verbose=0)
print(model.metrics_names[0] + '=', scores[0])
print(model.metrics_names[1] + '=', scores[1])

test_generator.reset()
probabilities = model.predict(test_generator, 
                              steps=STEP_SIZE_TEST,
                              verbose=0)
y_test = probabilities.argmax(axis=1)
y_pred = test_generator.classes
# target_names = sorted(os.listdir(dir_path + "/test"))
target_names = ["klasa F", "klasa N", "klasa Q", "klasa S", "klasa V"]
print(classification_report(y_test, y_pred, target_names=target_names))

cm = confusion_matrix(y_test, y_pred)
plot_confusion_matrix(cm, target_names, title="Macierz pomyłek", cmap=None, normalize=False)

# Zapisanie pliku .csv porównując typ i predykcję, jest podane zdjęcie więc łatwo będzie sprawdzić co z nim nie tak
test_generator.reset()
probabilities = model.predict(test_generator, 
                              steps=STEP_SIZE_TEST,
                              verbose=1)
predicted_class_indices = np.argmax(probabilities, axis=1)
labels = (train_generator.class_indices)
labels = dict((v, k) for k, v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]

filenames = test_generator.filenames
results=pd.DataFrame({"Filename": filenames,
                      "Predictions": predictions,})
results.to_csv("results.csv", sep=';', index=False)

# Zapisanie modelu do pliku
model.save('model_epoch13train_epoch2val.h5')

# Tworzenie schematu zawierającego kształt warstw.
from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, to_file="model.png")