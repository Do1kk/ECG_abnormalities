- może testy jakieś wprowadzić, tak jak jest w książce na przykład

- stworzyć jakieś bardziej uogólnione wczytywanie wyszukiwanie QRS, te co teraz jest 
bazuje na bazie MIT-BIH

- uzyc "Batch Norm" na kilku warstwach, przyspieszy uczenie ale da tez troche zakłuceń(to dobrze bo bedzie
wieksze val_acc)

- stworzyć optymalizator do kodu uczącego (keras itp) by zoptymalizować hiperparametry,
może rzeby dobierał jakieś i sprawdzał wyniki, może randomowo i zapisywał te najlepsze wyniki

- to chyba nie jest wydajne, 
        data = []
        data.append(np.array(all_data[:data_per_proc]))
        data.append(np.array(all_data[data_per_proc : data_per_proc * 2]))
        data.append(np.array(all_data[data_per_proc * 2 :]))

- poprawić sig_display.py

- zrobić coś z tym by nie przetwarzał pliku z którego pobiera zmienną

- zrobić jakiś program jak sig_dispaly ale żeby pokazywał jakie grupy i jakie typy do nich należą,
by można było wizualnie zauważyć podobieństaw tych typów w danej grupie

- tam w images zmienić type_... na group_... by nie myliło się z typami arytmii

- można by było zrobić jakąś obsługę błędów, np. gdy robię zdjęcie z 2 sygnałów by sprawdzało
czy licza wycinków się zgadza (musi być taka sama dla signal1 i signal2)

- coś zrobić żeby na przykład w nazwie modelu który jest zapisywany była liczba przeprowadzonych epoch,
pozwolało by to później jakoś zidentyfikować zmiany modelu

##########################################################
- odrzucenie dużej ilości zdjęć z grupy_N dla poprawienia szybkości oraz wyników

- użyć również drugiego sygnału (może połączyć razem z pierwszym i zrobić jeden obraz?) "klasyfikacja na podstawie 
dwóch sygnałów", pamiętać by modF był tak samo tworzony dla obu sygnałów

- przetworzyć również drugi sygnał i zapisać,

- może zrobić następny program co ma słownik tylko tych typów co mają małą ilość i tworzy nowe pliki csv
z danymi po modyfikacji, później dodać tylko te pliki do programu co tworzy zdjęcia
typy z małą ilością:
type_F - 802 (grupa F - 802)

- jeszcze raz przetestować dzieląc .8 .1 .1 ale dając mu dużo czasu, np ucząc kilka razy po 5h

- zapytać promotora jak podzielić dane, proporcionalnie czy jednak dać stałe liczyb w dev i test
dla każdego typu

- zapytać promotora czy może kontaktować się przez isod, wstawiać tam pliki i wgl

- zapytać promotora czy komentarze i zmienne po angielsku czy po polsku

- napisać instrukcję co po czym uruchamiać w tym projekcie

- zrobić testy jak się uczy dzieląć na train/dev/test np .8 .1 .1 i dająć np każdego typu 100 zdjęć do 
dev i 100 do test a resztę do train

- sprawdzić jak będzie z oversampling i jak bez, czyli wyniki w colab
słabe wyniki, uczył się na treningowych loss spadał i wzrastała dokładność, w dev(val) trzymało się na stałym pozimie
po jakimś 4-5 epoch (ok 1 val_loss i ok 0.8 val_acc)

- włączyć użycie tcp na colab

- importowanie zmiennyc/funkcji z innych plików by nie powtarzać kodu

- # Nowy podział na grupy:
# N <- non-ectopic,
# S <- supraventricular ectopic,
# V <- ventricular ectopic,
# F <- fusion beats,
# Q <- Unknown beats.
# co ciekawe zostały jeszcze typy "!, P, p".....

- brać zdjęcia wybiórczo (są brane z początku np dla typu N jest brane 2540 zdjęc z początku wszystkich 74tys),
teraz jest mięszane podczas podziału w image_split.py
- w png_spec.py ustawic by robił wszystkie typy zdjęć w pętli, jest mały problem z multiprocessingem

- przesunąć wycięte przedziały, dlatego że bicie serca nie jest wyśrodkowane do głównego peak (lewa 
strona jest krótsza a prawa dłuższa), w magisterce można podać obliczenia czemu taka długość przedziału
i czemu takie przesunięcie

- może dać opis do funkcji typu ''' dsfsdf '''

- może też dała by coś normalizacja danych pikseli (że podzielić wszytkie przez 255) ale wtedy trzeba zmienić 
typ danych z uint8 na inny (taki co przechowuje liczby z zakresu [0, 1], dodatkowo liczby zmienno przecinkowe 
są lepiej liczone przez GPU

- liczba batch (mini-batch) powinna być wielokrotnością 2, np 128

- zrobić w kers generatory, może szybciej będzie to działać, mniejsze użycie ramu,
można wtedy kożystać ze zdjęć a nie z spakowanego pliku numpy na podstwaie zdjęć, jest szybciej
i zostawia się wszystko bibliotece keras i tensorflow

- należy pamiętać że uzywany jest tylko jeden sygnał z dwóch, "klasyfikacja na podstawie 
jednego sygnału"

- opisać który program co robi, 

- stworzyć program który będzie wyświetlał 10 wykresów z każdego typu uderzeń

- ustawić pseudo losowość by wynik był powtarzalny (jest prawie powtarzalny) różnice są pewnie przez
GPU, podobno on nadaje jakieś losowe liczby również

- zapisać razem wszystkie dane a później je podzielić albo podzielić w sposób losowy

- sprawdzić zmienne y_train i y_test

- stworzyć zwykłą cnn głęboką sieć neuronową by sprawdzić jak działa na moich danych,
shape początkowy -> X_train (60000, 28, 28) <- macierz macierzy 28x28
shape początkowy -> y_train (60000,) <- lista cyfr 0..9 (można to w keras łatwo zamienić na wektor)

- Może wczytać z każdego typu po 2k zdjęć do treningu i później 0.5k do testów, a wyjście 
jako macierz wektorów (0 0 0 1 0 0)

- dać wszystko na githuba to można bedzie z niego wczytać do colaba

- zmniejszyć zdjęcia i zmienić na czarnobiałe, jest ich tyle że lepiej jak by 
były prostrze, np 470x470 jak było w tym wyjściowym wektorze (jest 496x369),
zmieniłem na 220x220 dalej rgb

- zapisać wszystkie obrazy z csv typów uderzeń serca

- użyć multiprocessing by przyśpieszyć wykonanie tworzenia zdjęć spektrogramu i zmiejszyć
wielkość zdjęcia (udało się zejść z 10h do 1h 30 min)

- utworzyć oddzielny folder na stare programy które są już nie potrzebne

- odrzucić typy uderzeń których jest za mało

- przeanalizować spektrogram, coś jest nie tak

- pogrupować przedziały na typy i zapisać do plików mających nazwy typów

- zamiast używania pętli i oznaczania wszystkiego co nie jest adnotacją peaks jako '0'
użyć funkcji filter([function | expression], [collection]) <- zwraca generator nie listę

- można stwożyć słownik (jeśli będzie potrzebny) za pomocą dict(zip(pierwsza_lista, druga_lista))

- poczytać o arytmii, czy na pewno w taki sposób można wyszukać wadę, tzn. czy można 
zrobić to patrząc tylko na zbiór wycinków, nie przetwarzając sygnału w całości

- uwzglęndić tylko te wzniesienia w adnotacjach które nie są błędne (jest chyba kilka adnotacji
które opisują błędy a nie wzniesienia)

- poprawienie dokładności preprocesingu, by lepiej znajdował wzniesienia,
najlepiej by wykożystywał adnotacje a nie sam szukał, chociaż takie wyszukiwanie też
się przyda np. jak będzie się chciało wykożystać sygnał z innej bazy, bez adnotacji

- może zrobić bez rozróżnienia dobrych wzniesień bo przecież i te złe wzniesienia są ważne,
a dopiero na samym końcu wywalić te co są błędne (błęd aparatury)

- zamiana ciągłego kodu na tak z użyciem funkcji, lepiej zmieniać i lepiej wygląda

- stworzenie programu który pokazuje stworzone pliki .csv jako obrazy,
widać na nich bardzo szybko czy dobrze zostały zebrane wzniesienia