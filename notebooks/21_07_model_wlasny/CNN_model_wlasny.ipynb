{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_model_wlasny.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "twzNoSWPocXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Użycie zapisanych na dysku zdjęć.\n",
        "!unzip -q '/content/drive/My Drive/train_val_test.zip' -d '/content'\n",
        "# Load the TensorBoard notebook extension. #%reload_ext tensorboard\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd4XyCKVpZ8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8ee3a264-ece7-4045-acde-69941481ae83"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(2)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adamax, Nadam, Ftrl, Adadelta\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "INITIAL_EPOCH = 0\n",
        "IMG_HEIGHT, IMG_WIDTH, CHANNELS = 220, 220, 3\n",
        "\n",
        "dir_path = \"/content/train_val_test\"\n",
        "root = \"/content/drive/My Drive/CNN_model_wlasny/\" \n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1.0/255.)\n",
        "val_gen = ImageDataGenerator(rescale=1.0/255.)\n",
        "test_gen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "    dir_path + '/train',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    seed=2)\n",
        "validation_generator = val_gen.flow_from_directory(\n",
        "    dir_path + '/val',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    seed=2)\n",
        "test_generator = test_gen.flow_from_directory(\n",
        "    dir_path + '/test',\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode='categorical',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    seed=2)\n",
        "\n",
        "STEP_SIZE_TRAIN = train_generator.n // train_generator.batch_size\n",
        "STEP_SIZE_VALID = validation_generator.n // validation_generator.batch_size\n",
        "\n",
        "my_callbacks = [\n",
        "    ModelCheckpoint(filepath=root + \"model.{epoch:02d}.h5\",\n",
        "                    monitor=\"val_accuracy\",\n",
        "                    mode='max',\n",
        "                    save_best_only=True,\n",
        "                    save_freq=\"epoch\",),\n",
        "    TensorBoard(log_dir=root + \"logs\",\n",
        "                write_images=False,\n",
        "                histogram_freq=1,\n",
        "                embeddings_freq=2),\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22461 images belonging to 5 classes.\n",
            "Found 7559 images belonging to 5 classes.\n",
            "Found 6221 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmu6jhaZpHd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfc0c19e-60e8-470b-ca09-b8b26ade2459"
      },
      "source": [
        "# Użycie zapisanego na dysku modelu.\n",
        "files = [f for f in sorted(os.listdir(root))]\n",
        "model_file = files[-1]\n",
        "INITIAL_EPOCH = int(model_file.split('.')[1])\n",
        "EPOCHS += INITIAL_EPOCH\n",
        "    \n",
        "model = load_model(root + model_file)\n",
        "print(f\"Wczytanie pliku modelu: {model_file}, z ilością EPOCH: {INITIAL_EPOCH}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wczytanie pliku modelu: model.33.h5, z ilością EPOCH: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9MIAXe3q0Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Tworzenie modelu. Jeśli model jest wczytywany to nie tworzyć bo to go usunie.\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(8, kernel_size=3, activation=\"relu\", \n",
        "#                  input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
        "#                  data_format=\"channels_last\"))\n",
        "# model.add(Conv2D(8, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(8, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(16, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Conv2D(16, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(5, activation=\"softmax\"))\n",
        "# model.compile(optimizer=Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07), \n",
        "#               loss=\"categorical_crossentropy\", \n",
        "#               metrics=[\"accuracy\"])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ72ni2By8tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tworzenie modelu. Jeśli model jest wczytywany to nie tworzyć bo to go usunie.\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\", \n",
        "                 input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS), \n",
        "                 data_format=\"channels_last\"))\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "# model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation=\"softmax\"))\n",
        "model.compile(optimizer=Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07), \n",
        "              loss=\"categorical_crossentropy\", \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i2EI0dgcbRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "074ed1de-23c0-4e0f-fee3-febc33e5d614"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 218, 218, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 216, 216, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 216, 216, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 214, 214, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 107, 107, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 105, 105, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 103, 103, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 103, 103, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 101, 101, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 48, 48, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 18, 18, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 18, 18, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 128)         147584    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 793,381\n",
            "Trainable params: 792,741\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrnF78cffQN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Włączenie tensorboard.\n",
        "%tensorboard --logdir \"/content/drive/My Drive/CNN_model_wlasny/logs\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoG7NVyZp-XA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c00e4ff2-1287-4751-e8c6-a6f9816f1bf2"
      },
      "source": [
        "history = model.fit(train_generator, \n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=EPOCHS, shuffle=True,\n",
        "                    callbacks=my_callbacks,\n",
        "                    initial_epoch=INITIAL_EPOCH,\n",
        "                    use_multiprocessing=False, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "701/701 [==============================] - 82s 117ms/step - loss: 0.7433 - accuracy: 0.7010 - val_loss: 0.6932 - val_accuracy: 0.7251\n",
            "Epoch 2/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.4172 - accuracy: 0.8482 - val_loss: 0.4712 - val_accuracy: 0.8341\n",
            "Epoch 3/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.3267 - accuracy: 0.8840 - val_loss: 0.4429 - val_accuracy: 0.8584\n",
            "Epoch 4/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.2798 - accuracy: 0.9003 - val_loss: 0.2727 - val_accuracy: 0.8988\n",
            "Epoch 5/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.2494 - accuracy: 0.9119 - val_loss: 0.4783 - val_accuracy: 0.8436\n",
            "Epoch 6/50\n",
            "701/701 [==============================] - 80s 115ms/step - loss: 0.2254 - accuracy: 0.9205 - val_loss: 0.2731 - val_accuracy: 0.9039\n",
            "Epoch 7/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.2120 - accuracy: 0.9250 - val_loss: 0.2608 - val_accuracy: 0.9028\n",
            "Epoch 8/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.2019 - accuracy: 0.9284 - val_loss: 0.2976 - val_accuracy: 0.9011\n",
            "Epoch 9/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.1887 - accuracy: 0.9345 - val_loss: 0.2913 - val_accuracy: 0.8966\n",
            "Epoch 10/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.1766 - accuracy: 0.9376 - val_loss: 0.3671 - val_accuracy: 0.8661\n",
            "Epoch 11/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.1742 - accuracy: 0.9382 - val_loss: 0.3069 - val_accuracy: 0.8880\n",
            "Epoch 12/50\n",
            "701/701 [==============================] - 81s 116ms/step - loss: 0.1530 - accuracy: 0.9458 - val_loss: 0.3079 - val_accuracy: 0.9073\n",
            "Epoch 13/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1461 - accuracy: 0.9483 - val_loss: 0.2983 - val_accuracy: 0.9068\n",
            "Epoch 14/50\n",
            "701/701 [==============================] - 80s 115ms/step - loss: 0.1478 - accuracy: 0.9484 - val_loss: 0.2701 - val_accuracy: 0.9089\n",
            "Epoch 15/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1356 - accuracy: 0.9521 - val_loss: 0.3506 - val_accuracy: 0.8890\n",
            "Epoch 16/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1236 - accuracy: 0.9552 - val_loss: 0.2060 - val_accuracy: 0.9301\n",
            "Epoch 17/50\n",
            "701/701 [==============================] - 80s 115ms/step - loss: 0.1216 - accuracy: 0.9551 - val_loss: 0.2875 - val_accuracy: 0.9055\n",
            "Epoch 18/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1159 - accuracy: 0.9580 - val_loss: 0.2274 - val_accuracy: 0.9329\n",
            "Epoch 19/50\n",
            "701/701 [==============================] - 81s 116ms/step - loss: 0.1159 - accuracy: 0.9591 - val_loss: 0.3136 - val_accuracy: 0.9076\n",
            "Epoch 20/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1028 - accuracy: 0.9618 - val_loss: 0.2531 - val_accuracy: 0.9264\n",
            "Epoch 21/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.1153 - accuracy: 0.9592 - val_loss: 0.3700 - val_accuracy: 0.8893\n",
            "Epoch 22/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.0999 - accuracy: 0.9635 - val_loss: 0.2526 - val_accuracy: 0.9268\n",
            "Epoch 23/50\n",
            "701/701 [==============================] - 81s 116ms/step - loss: 0.0926 - accuracy: 0.9656 - val_loss: 0.4319 - val_accuracy: 0.8998\n",
            "Epoch 24/50\n",
            "701/701 [==============================] - 81s 116ms/step - loss: 0.0948 - accuracy: 0.9653 - val_loss: 0.2300 - val_accuracy: 0.9270\n",
            "Epoch 25/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.0808 - accuracy: 0.9702 - val_loss: 0.3185 - val_accuracy: 0.9150\n",
            "Epoch 26/50\n",
            "701/701 [==============================] - 82s 117ms/step - loss: 0.0828 - accuracy: 0.9698 - val_loss: 0.7699 - val_accuracy: 0.8473\n",
            "Epoch 27/50\n",
            "701/701 [==============================] - 82s 116ms/step - loss: 0.0963 - accuracy: 0.9676 - val_loss: 0.3398 - val_accuracy: 0.9149\n",
            "Epoch 28/50\n",
            "701/701 [==============================] - 81s 115ms/step - loss: 0.0779 - accuracy: 0.9721 - val_loss: 0.2839 - val_accuracy: 0.9289\n",
            "Epoch 29/50\n",
            "701/701 [==============================] - 82s 116ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.3518 - val_accuracy: 0.9236\n",
            "Epoch 30/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0699 - accuracy: 0.9751 - val_loss: 0.3579 - val_accuracy: 0.9149\n",
            "Epoch 31/50\n",
            "701/701 [==============================] - 79s 113ms/step - loss: 0.0647 - accuracy: 0.9776 - val_loss: 0.4178 - val_accuracy: 0.9172\n",
            "Epoch 32/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0832 - accuracy: 0.9728 - val_loss: 0.2784 - val_accuracy: 0.9257\n",
            "Epoch 33/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0609 - accuracy: 0.9780 - val_loss: 0.2469 - val_accuracy: 0.9343\n",
            "Epoch 34/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.3307 - val_accuracy: 0.9159\n",
            "Epoch 35/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.3961 - val_accuracy: 0.9195\n",
            "Epoch 36/50\n",
            "701/701 [==============================] - 80s 115ms/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 0.3015 - val_accuracy: 0.9277\n",
            "Epoch 37/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.4112 - val_accuracy: 0.9240\n",
            "Epoch 38/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 0.6058 - val_accuracy: 0.8672\n",
            "Epoch 39/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.3725 - val_accuracy: 0.9296\n",
            "Epoch 40/50\n",
            "701/701 [==============================] - 80s 114ms/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.3116 - val_accuracy: 0.9326\n",
            "Epoch 41/50\n",
            "701/701 [==============================] - 79s 113ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.3851 - val_accuracy: 0.9315\n",
            "Epoch 42/50\n",
            "701/701 [==============================] - 80s 113ms/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 0.4085 - val_accuracy: 0.9170\n",
            "Epoch 43/50\n",
            "701/701 [==============================] - 78s 112ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.3538 - val_accuracy: 0.9278\n",
            "Epoch 44/50\n",
            "701/701 [==============================] - 78s 111ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.3463 - val_accuracy: 0.9297\n",
            "Epoch 45/50\n",
            "701/701 [==============================] - 78s 111ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.4340 - val_accuracy: 0.9153\n",
            "Epoch 46/50\n",
            "701/701 [==============================] - 79s 112ms/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 0.8858 - val_accuracy: 0.9139\n",
            "Epoch 47/50\n",
            "701/701 [==============================] - 79s 113ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.4812 - val_accuracy: 0.8931\n",
            "Epoch 48/50\n",
            "701/701 [==============================] - 79s 113ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.3324 - val_accuracy: 0.9224\n",
            "Epoch 49/50\n",
            "701/701 [==============================] - 78s 112ms/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.4813 - val_accuracy: 0.9084\n",
            "Epoch 50/50\n",
            "701/701 [==============================] - 78s 112ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.3571 - val_accuracy: 0.9237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GWJSFEqFwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "70a1d85d-3213-438a-832b-fa403cc31da3"
      },
      "source": [
        "# Sprawdzenie poprawności na danych testowych\n",
        "test_generator.reset()\n",
        "STEP_SIZE_TEST = test_generator.n // test_generator.batch_size \n",
        "scores = model.evaluate(test_generator, \n",
        "                        steps=STEP_SIZE_TEST,\n",
        "                        verbose=0)\n",
        "print(model.metrics_names[0] + \" = \", scores[0])\n",
        "print(model.metrics_names[1] + \" = \", scores[1])\n",
        "\n",
        "test_generator.reset()\n",
        "probabilities = model.predict(test_generator, \n",
        "                              steps=STEP_SIZE_TEST,\n",
        "                              verbose=0)\n",
        "y_test = probabilities.argmax(axis=1)\n",
        "y_pred = test_generator.classes\n",
        "target_names = sorted(os.listdir(dir_path + \"/test\"))\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss =  0.26323002576828003\n",
            "accuracy =  0.9347372055053711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      type_F       0.86      0.81      0.83       171\n",
            "      type_N       0.91      0.94      0.93      2324\n",
            "      type_Q       0.99      0.99      0.99      1602\n",
            "      type_S       0.87      0.74      0.80       713\n",
            "      type_V       0.94      0.97      0.95      1411\n",
            "\n",
            "    accuracy                           0.93      6221\n",
            "   macro avg       0.92      0.89      0.90      6221\n",
            "weighted avg       0.93      0.93      0.93      6221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI6Fbbdsqn6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b7c57e4-3202-42a7-cd8b-b25e35b21d55"
      },
      "source": [
        "# Zapisanie pliku .csv porównując typ i predykcję, jest podane zdjęcie więc łatwo będzie sprawdzić co z nim nie tak\n",
        "test_generator.reset()\n",
        "probabilities = model.predict(test_generator, \n",
        "                              steps=STEP_SIZE_TEST,\n",
        "                              verbose=1)\n",
        "predicted_class_indices = np.argmax(probabilities, axis=1)\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v, k) for k, v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\": filenames,\n",
        "                      \"Predictions\": predictions,})\n",
        "results.to_csv(\"results.csv\", sep=';', index=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6221/6221 [==============================] - 42s 7ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}